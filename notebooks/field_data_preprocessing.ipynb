{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a135e1-789a-4395-98cb-a5afb792514d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40d912-a00b-493c-80c3-48b270b9dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression, RFECV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "import miceforest as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "field_data_file = data_dir + 'field_data.csv'\n",
    "results_file = data_dir + 'field_data_imputed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3253e64",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_agb(row):\n",
    "    diameter = row['diameter']\n",
    "    species = row['group']\n",
    "    if species == 'banana':\n",
    "        agb = 0.03 * diameter ** 2.13\n",
    "    elif species == 'cacao':\n",
    "        agb = 0.1208 * diameter ** 1.98\n",
    "    elif species == 'fruit':\n",
    "        agb = 0.0776 * diameter ** 2.64\n",
    "    elif species == 'citrus':\n",
    "        agb = 0.0776 * diameter ** 2.64\n",
    "    elif species == 'timber':\n",
    "        agb = 21.3 - 6.95 * diameter + 0.74 * diameter ** 2\n",
    "    else:\n",
    "        agb = 0.1466 * diameter ** 2.223\n",
    "    return agb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b7ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_carbon(agb, rsr=0.22):\n",
    "    return agb / (2 * (1 - rsr))  # equivalent to agb * 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c5494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_categorical(df, column_name):\n",
    "    df[column_name] = pd.Categorical(df[column_name]).cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ce65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(df, column_name):\n",
    "    categories = pd.get_dummies(df[column_name])\n",
    "    categories.columns = [f'{column_name}_{category_name}' for category_name in categories.columns]\n",
    "    df = pd.concat([df, categories], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c924950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name = 'field_data.csv', modify_columns=True, verbose=False):\n",
    "    data_dir = '../data/'\n",
    "    field_data_file = data_dir + file_name\n",
    "    df = pd.read_csv(field_data_file, na_values='')\n",
    "    df['diameter'] = df['diameter'].map(lambda x: float(x) if x != 0 else np.nan)\n",
    "    if modify_columns:\n",
    "        df = df.drop(columns=['lat', 'lon', 'site', 'X', 'Y', 'updated diameter', 'AGB', 'carbon'])\n",
    "        df['year'] = df['year'].map(lambda x: int(x) - 2016)\n",
    "        df['height'] = df['height'].map(lambda x: float(x))\n",
    "        df['plot_id'] = df['plot_id'].map(lambda x: int(x[1:]))\n",
    "        df = make_one_hot(df, 'name')\n",
    "        df = make_one_hot(df, 'group')\n",
    "        df = make_one_hot(df, 'plot_id')\n",
    "        df = df.drop(columns=['name', 'group', 'plot_id'])\n",
    "    if verbose:\n",
    "        print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(clean_df, verbose=False):\n",
    "    df = pd.read_csv(field_data_file, na_values='')\n",
    "    df = df.drop(columns=['updated diameter'])\n",
    "    df['diameter'] = clean_df['diameter']\n",
    "    df['AGB'] = df.apply(lambda row: compute_agb(row), axis=1)\n",
    "    df['carbon'] = compute_carbon(df['AGB'])\n",
    "    df.to_csv(results_file, index=False)\n",
    "    if verbose:\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e9ea5",
   "metadata": {},
   "source": [
    "## Explore missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3824f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/field_data.csv', na_values=0)\n",
    "print(sum(df['height'] > 0))  # Number of height values in dataset\n",
    "print((df['diameter'] > 0).sum())  # Number of diameter values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4edd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species_group_names = sorted(df.group.unique())\n",
    "for species_group_name in all_species_group_names:\n",
    "    print(species_group_name)\n",
    "    print(f'{len(df[df.group == species_group_name]) / 4663 * 100}%')  # Percentage of trees in this group\n",
    "    print(len(df[df.group == species_group_name]))  # Number of trees in this group\n",
    "    print((df[df.group == species_group_name]['diameter'] > 0).sum())  # Number of trees in this group with diameter values\n",
    "    print(len(df[(df['group'] == species_group_name) & (df['diameter'].isna())]))  # Same, but without diameter\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19116d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_species_names = sorted(df.name.unique())\n",
    "for species_name in all_species_names:\n",
    "    print(species_name)\n",
    "    print(f'{len(df[df.name == species_name]) / 4663 * 100}%')  # Percentage of trees in this species\n",
    "    print(len(df[df.name == species_name]))  # Number of trees in this species\n",
    "    print((df[df.name == species_name]['diameter'] > 0).sum())  # Number of trees in this species with diameter values\n",
    "    print(len(df[(df['name'] == species_name) & (df['diameter'].isna())]))  # Same, but without diameter\n",
    "    print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9f862d",
   "metadata": {},
   "source": [
    "## Explore outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0659f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in ['diameter', 'AGB']:\n",
    "    sorted_column = df[column_name].dropna().sort_values()\n",
    "    print(f'{column_name[0].capitalize() + column_name[1:]} values:\\n')\n",
    "    print(f'min={sorted_column.min()}, max={sorted_column.max()}, mean={sorted_column.mean()}, std={sorted_column.std()}\\n')\n",
    "    print(sorted_column[:20].to_numpy(), '\\n')  # Smallest 20 values\n",
    "    print(sorted_column[-20:].to_numpy(), '\\n')  # Largest 20 values\n",
    "    print('=' * 100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82cd234-f37e-45ab-9a06-5a4569dae41e",
   "metadata": {},
   "source": [
    "## Start data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4838f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287dc99",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adb719-1285-48fa-992d-239a793f10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute(df, method='simple', strategy='median', n_neighbors=10, weights='uniform', metric='nan_euclidean',\n",
    "           save_all_iterations=False, iterations=100, n_estimators=100, verbose=False):\n",
    "    if method == 'mice':\n",
    "        imputer = mf.ImputationKernel(df, save_all_iterations=False)\n",
    "        imputer.mice(iterations=100, n_estimators=100, n_jobs=-1)\n",
    "        imputed_df = imputer.complete_data()\n",
    "    else:\n",
    "        if method == 'simple':\n",
    "            imputer = SimpleImputer()\n",
    "        elif method == 'knn':\n",
    "            imputer = KNNImputer(n_neighbors=n_neighbors, weights=weights, metric=metric)\n",
    "        else:\n",
    "            print(f'Unknown imputation method \"{method}\". Valid options: simple, knn, mice.')\n",
    "            return df\n",
    "        imputed_df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "    if verbose:\n",
    "        print(imputed_df)\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = impute(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b1b564",
   "metadata": {},
   "source": [
    "## Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82564ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(df, method='simple', n_estimators=100, max_features=1.0, n_jobs=-1, verbose=False):\n",
    "    if method == 'simple':\n",
    "        clean_df = df[(df['diameter'] > 1.5) & (df['diameter'] < 30)]\n",
    "    elif method == 'isolation_forests':\n",
    "        isolation_forest = IsolationForest(n_estimators=n_estimators, max_features=max_features, n_jobs=n_jobs).fit(df)\n",
    "        outliers_indices = isolation_forest.predict(df)\n",
    "        clean_df = df[outliers_indices == 1]\n",
    "    else:\n",
    "        print(f'Unknown outlier detection method \"{method}\". Valid options: simple, isolation_forests.')\n",
    "        return df\n",
    "    if verbose:\n",
    "        print(imputed_df)\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef1faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = outlier_removal(imputed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ab838",
   "metadata": {},
   "source": [
    "## Save final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(clean_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
