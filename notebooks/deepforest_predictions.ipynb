{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree detection with DeepForest\n",
    "In this notebook, we reproduce the results of tree detection step of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Generator\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from deepforest import deepforest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define class for extracting patches from large RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGenerator:\n",
    "    def __init__(self, image: np.ndarray, patch_shape: Tuple[int, int]) -> None:\n",
    "        self.image = image\n",
    "        self.height, self.width, self.num_channels = self.image.shape\n",
    "        self.patch_shape = patch_shape\n",
    "        self._extract_patches()\n",
    "\n",
    "    def __call__(self) -> Generator[np.ndarray, None, None]:\n",
    "        for idx in range(self._calculate_num_patches()):\n",
    "            yield self.patches[idx, :, :, :]\n",
    "\n",
    "    def get_patch(self, idx: int) -> np.ndarray:\n",
    "        return self.patches[idx, :, :, :]\n",
    "\n",
    "    def get_patch_tl_br(self, idx: int) -> Tuple[int, int, int, int]:\n",
    "        i, j = self._calculate_patch_coord(idx)\n",
    "        v_start, v_end = i * self.patch_shape[0], (i + 1) * self.patch_shape[0]\n",
    "        u_start, u_end = j * self.patch_shape[1], (j + 1) * self.patch_shape[1]\n",
    "        return u_start, v_start, u_end, v_end\n",
    "\n",
    "    def get_num_patches(self) -> int:\n",
    "        return self._calculate_num_patches()\n",
    "\n",
    "    def stitch_patches(self, patches: np.ndarray = None) -> np.ndarray:\n",
    "        if patches is None:\n",
    "            patches = self.patches\n",
    "        stiched_image = np.zeros_like(self.image)\n",
    "        for idx in range(self._calculate_num_patches()):\n",
    "            u_start, v_start, u_end, v_end = self.get_patch_tl_br(idx)\n",
    "            patch_shape = stiched_image[v_start:v_end, u_start:u_end, :].shape\n",
    "            stiched_image[v_start:v_end, u_start:u_end, :] = patches[idx, :patch_shape[0], :patch_shape[1], :]\n",
    "        return stiched_image\n",
    "\n",
    "    def _extract_patches(self) -> np.ndarray:\n",
    "        num_patches = self._calculate_num_patches()\n",
    "        self.patches = np.zeros((num_patches, *self.patch_shape, self.num_channels))\n",
    "\n",
    "        for idx in range(num_patches):\n",
    "            u_start, v_start, u_end, v_end = self.get_patch_tl_br(idx)\n",
    "            patch = self.image[v_start:v_end, u_start:u_end, :]\n",
    "            patch_height, patch_width, _ = patch.shape\n",
    "            self.patches[idx, :patch_height, :patch_width, :] = patch\n",
    "\n",
    "    def _calculate_num_rows_columns(self) -> Tuple[int, int]:\n",
    "        num_rows = ceil(self.height / self.patch_shape[0])\n",
    "        num_columns = ceil(self.width / self.patch_shape[1])\n",
    "        return num_rows, num_columns\n",
    "\n",
    "    def _calculate_patch_coord(self, idx: int) -> Tuple[int, int]:\n",
    "        _, num_columns = self._calculate_num_rows_columns()\n",
    "        row_idx = idx // num_columns\n",
    "        col_idx = idx % num_columns\n",
    "        return row_idx, col_idx\n",
    "\n",
    "    def _calculate_num_patches(self) -> int:\n",
    "        num_rows, num_columns = self._calculate_num_rows_columns()\n",
    "        return num_rows * num_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define method for loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_filepath: str) -> np.ndarray:\n",
    "    return cv2.imread(image_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use deepforest model to predict bounding boxes of tree crowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILEPATH = \"./models/final_model_4000_epochs_35.h5\"\n",
    "PREDICTION_OUTPUT_DIR = \"./data/processed/predicted_bbox\"\n",
    "PATCH_SHAPE = (4000, 4000)\n",
    "SCORE_THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deepforest.deepforest(saved_model=MODEL_FILEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to predict boudning boxes for given orthomosaic (RGB image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bounding_boxes(orthomosaic_filepath):\n",
    "    orthomosaic = load_image(orthomosaic_filepath)\n",
    "    patch_generator = PatchGenerator(orthomosaic, PATCH_SHAPE)\n",
    "    prediction: pd.DataFrame = None\n",
    "    for idx, patch in enumerate(patch_generator()):\n",
    "        pred = model.predict_image(\n",
    "            numpy_image=patch, return_plot=False, score_threshold=SCORE_THRESHOLD\n",
    "        )\n",
    "        # Transform bounding box cooords from patch to orthomosaic\n",
    "        vmin, umin, _, _ = patch_generator.get_patch_tl_br(idx)\n",
    "        pred['xmin'] = pred['xmin'] + vmin\n",
    "        pred['xmax'] = pred['xmax'] + vmin\n",
    "        pred['ymin'] = pred['ymin'] + umin\n",
    "        pred['ymax'] = pred['ymax'] + umin\n",
    "        prediction = pd.concat([prediction, pred], ignore_index=True)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(prediction: pd.DataFrame, orthomosaic_filepath):\n",
    "    orthomosaic_filename = os.path.splitext(os.path.basename(orthomosaic_filepath))[0]\n",
    "    output_filename = os.path.join(PREDICTION_OUTPUT_DIR, f\"{orthomosaic_filename}_predicted_bounding_boxes.csv\")\n",
    "    prediction.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthomosaic_filepaths = [\n",
    "    \"./data/raw/Carlos Vera Arteaga RGB.tif\",\n",
    "    \"./data/raw/Carlos Vera Guevara RGB.tif\",\n",
    "    \"./data/raw/Flora Pluas RGB.tif\",\n",
    "    \"./data/raw/Leonor Aspiazu RGB.tif\",\n",
    "    \"./data/raw/Manuel Macias RGB.tif\",\n",
    "    \"./data/raw/Nestor Macias RGB.tif\",\n",
    "]\n",
    "\n",
    "for orthomosaic_filepath in tqdm(orthomosaic_filepaths):\n",
    "    predictions = predict_bounding_boxes(orthomosaic_filepath)\n",
    "    print(predictions.head())\n",
    "    save_predictions(predictions, orthomosaic_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to generate visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORTHOMOSAICS_DIR = \"./data/raw/\"\n",
    "VISUALIZATION_OUTPUT_DIR = \"./data/processed/predicted_bbox_visualizations\"\n",
    "COLOR = (0, 0, 255)\n",
    "THICKNESS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bounding_boxes(orthomosaic_name):\n",
    "    # Load deepforest predictions\n",
    "    prediction_filename = f\"{orthomosaic_name}_predicted_bounding_boxes.csv\"\n",
    "    prediction_filepath = os.path.join(PREDICTION_OUTPUT_DIR, prediction_filename)\n",
    "    predictions = pd.read_csv(prediction_filepath)\n",
    "    # Load RGB orthomosaic\n",
    "    ortho_filename = f\"{orthomosaic_name}.tif\"\n",
    "    ortho_filepath = os.path.join(ORTHOMOSAICS_DIR, ortho_filename)\n",
    "    image = load_image(ortho_filepath)\n",
    "    # Draw bounding boxes\n",
    "    for _, row in predictions.iterrows():\n",
    "        p1 = (int(row.xmin), int(row.ymin))\n",
    "        p2 = (int(row.xmax), int(row.ymax))\n",
    "        image = cv2.rectangle(image, p1, p2, COLOR, THICKNESS)\n",
    "    # Save visualizations\n",
    "    output_filename = f\"{orthomosaic_name}_predicted_boxes.png\"\n",
    "    output_filepath = os.path.join(VISUALIZATION_OUTPUT_DIR, output_filename)\n",
    "    cv2.imwrite(output_filepath, image)\n",
    "    image_compressed = cv2.resize(image, None, fx=0.1, fy=0.1)\n",
    "    output_filename = f\"{VISUALIZATION_OUTPUT_DIR}_predicted_boxes_compressed.png\"\n",
    "    output_filepath = os.path.join(VISUALIZATION_OUTPUT_DIR, output_filename)\n",
    "    cv2.imwrite(output_filepath, image_compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw and save visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "orthomosaic_names = [\n",
    "    \"Carlos Vera Arteaga RGB\",\n",
    "    \"Carlos Vera Guevara RGB\",\n",
    "    \"Flora Pluas RGB\",\n",
    "    \"Leonor Aspiazu RGB\",\n",
    "    \"Manuel Macias RGB\",\n",
    "    \"Nestor Macias RGB\",\n",
    "]\n",
    "for ortho_name in tqdm(orthomosaic_names):\n",
    "    visualize_bounding_boxes(ortho_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
